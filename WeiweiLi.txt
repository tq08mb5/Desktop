Three problems on privacy
by Weiwei Li

I wish everyone’s online privacy could be protected well.

The first problem on privacy is that designing for privacy can be quite difficult in practice. For one thing, pervasive computing technologies break our everyday conception of space and time, making it easy to intentionally, accidentally, or even maliciously share things that were done in one context with people in completely different contexts. A recent example of this phenomenon is the area of ambient assisted living, which aims to help the elderly continue living independently while still receiving emergency care should the "smart home" detect a life-threatening situation (such as a heart attack or a fall). Clearly, criminals might want access to such data to plan break-ins, and insurance companies might want this information to catch fraudulent claims. But even trusted family members might accidentally receive access to recordings of private moments that were never intended to be shared.
There has been no good solution to this problem. I think there should be producers of smart home applications that would like spend millions of dollars to update their products to overcome this problem and the customers (people or companies) having specials requirements also would like pay more for that.
I think the solution could be that to classify the encrypted data collected by any source and make the exact decisions with the help of deep learning.

The second problem on privacy is that ubiquitous computing technologies can also clash with social norms, thus causing friction. A prime example is Google Glass, the wearable device that not only accepts voice commands to present its owners with information in a convenient heads-up display but also supports the hands-free taking of pictures and videos. Although there's potential value from people using Google Glass, the clear majority of news stories surrounding the product to date have focused on the associated privacy concerns. Whereas, Google hails people wearing Glass as "Explorers," public discourse is increasingly calling them "glassholes." Indeed, some bars and restaurants have even started to ban patrons from wearing Glass, and several Explorers have reported being physically abused because they were wearing them.
There has been no good solution to this problem. I think there should be producers of wearable devices that would like spend millions of dollars to update their products to overcome this problem and the customers (people or companies) having specials requirements also would like pay more for that.
I think online AI could help determine if the person captured by wearable devices are willing to be recorded by the interactions between him and the holder of this device. If not, the device can blur the private content automatically.

The third problem on privacy is sustainable revenue models. Many developers offer smartphone apps for free, for example, and use advertising to generate money. However, going down this route provides a strong incentive for a company to collect more and more information about its users to better target advertisements. As we're already seeing with online behavioral advertising, this approach can yield higher revenues, but it also surprises many people and makes them feel they're being tracked. Online social networks such as Facebook and Google Plus are frequently under public scrutiny for their use of user data. Even if you trust the original data collector, once such data is disclosed to others — perhaps through a corporate takeover or an involuntary data spill — it's impossible to "get it back."
There has been no good solution to this problem. I think there should be Internet data service providers that would like spend millions of dollars to update their products to overcome this problem and the customers (people or companies) having specials requirements also would like pay more for that.
I think that the data can only be collected without any private content and must be bought (or got with rewards) from users with their own agreement.

